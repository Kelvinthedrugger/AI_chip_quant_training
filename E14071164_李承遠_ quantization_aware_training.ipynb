{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlr1xlJoKec0"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "43xdyzFuKaTc"
      },
      "outputs": [],
      "source": [
        "! pip install -q tensorflow\n",
        "! pip install -q tensorflow-model-optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "I6NzNPbBslOH",
        "outputId": "188ec074-9d96-490a-e637-f1084a71ea63"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.8.0'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvC-GGBoslOO",
        "outputId": "391bca0f-2cab-48e4-e7cb-612c90b6248a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((60000, 28, 28), (10000, 28, 28))"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(x_train,y_train),(x_test,y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "x_train = x_train / 255.\n",
        "x_test = x_test / 255.\n",
        "\n",
        "x_train.shape, x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jupUM0NvslOR"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, InputLayer, Reshape, Conv2D, Flatten, BatchNormalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNYvWUYbqC3L"
      },
      "source": [
        "### BatchNorm should be RIGHT AFTER Conv layer (should be in front of activation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "G73US2X1qC3Q"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1ddnoa6nqC3S"
      },
      "outputs": [],
      "source": [
        "def conv_block(model,filters):\n",
        "    model.add(Conv2D(filters=filters,kernel_size=(3,3)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(layers.Activation(activations.relu))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcTAr_3url1c"
      },
      "source": [
        "### Notice the strings of model declaration via Sequential API here, we'll investigate the behavior afterwards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PNbQoE1slOV",
        "outputId": "f30a023e-50c0-48f7-ac50-3dea69bd980c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape (Reshape)           (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 26, 26, 3)         30        \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 26, 26, 3)        12        \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 26, 26, 3)         0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 24, 24, 8)         224       \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 24, 24, 8)        32        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 24, 24, 8)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4608)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 15)                69135     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 15)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                160       \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 69,593\n",
            "Trainable params: 69,571\n",
            "Non-trainable params: 22\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "model = Sequential([\n",
        "    InputLayer(input_shape=(28,28)),\n",
        "    # RESHAPE LAYER IS IMPORTANT FOR QUANTIZATION\n",
        "    Reshape(target_shape=(28,28,1)),\n",
        "\n",
        "    Conv2D(filters=8, kernel_size=(3, 3),activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    ReLU(),\n",
        "\n",
        "    Conv2D(filters=8, kernel_size=(3, 3),activation='relu'),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(units=15, activation='relu'),\n",
        "    Dense(units=10, activation=\"softmax\"),    \n",
        "])\n",
        "\"\"\"\n",
        "model = Sequential()\n",
        "\n",
        "model.add(InputLayer(input_shape=(28,28)))\n",
        "model.add(Reshape(target_shape=(28,28,1)))\n",
        "\n",
        "conv_block(model,filters=3)\n",
        "\n",
        "conv_block(model,filters=8)\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(15))\n",
        "model.add(layers.Activation(activations.relu))\n",
        "\n",
        "model.add(Dense(10))\n",
        "model.add(layers.Activation(activations.softmax))\n",
        "\n",
        "model.build(input_shape=(28,28))\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOSo04XlqC3V",
        "outputId": "29d3dbde-1769-4694-e784-0c862c0af411"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "750/750 [==============================] - 8s 8ms/step - loss: 0.4941 - accuracy: 0.8220 - val_loss: 0.3959 - val_accuracy: 0.8543\n",
            "Epoch 2/5\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.3406 - accuracy: 0.8777 - val_loss: 0.3514 - val_accuracy: 0.8696\n",
            "Epoch 3/5\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.2908 - accuracy: 0.8939 - val_loss: 0.3282 - val_accuracy: 0.8792\n",
            "Epoch 4/5\n",
            "750/750 [==============================] - 5s 6ms/step - loss: 0.2603 - accuracy: 0.9055 - val_loss: 0.3372 - val_accuracy: 0.8803\n",
            "Epoch 5/5\n",
            "750/750 [==============================] - 5s 6ms/step - loss: 0.2334 - accuracy: 0.9135 - val_loss: 0.3412 - val_accuracy: 0.8792\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "_ = model.fit(x_train,y_train,epochs=5,validation_split=0.2,batch_size=64,verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uLMXzKP0JFx7"
      },
      "outputs": [],
      "source": [
        "# define helper function to evaluate the inputed model quick\n",
        "def model_eval(model):\n",
        "    los,acc = model.evaluate(x_test,y_test)\n",
        "    print(\"test loss: %.4f, test accuracy: %.4f\" % (los,acc))\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muBqpD51slOb",
        "outputId": "3bf5d049-a3ef-4e25-d6fd-78fbc819bfd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3574 - accuracy: 0.8758\n",
            "test loss: 0.3574, test accuracy: 0.8758\n"
          ]
        }
      ],
      "source": [
        "test_acc = model_eval(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OryzNpJX_fCw"
      },
      "source": [
        "### For later usage and experiment, we define following helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPoueEsp_i-z",
        "outputId": "cc309581-7ea0-454c-8cf6-560b4269bdcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.21.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyyaml h5py "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3uCCQyoQ_sI-"
      },
      "outputs": [],
      "source": [
        "import tempfile\n",
        "\n",
        "def get_model():\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(InputLayer(input_shape=(28,28)))\n",
        "  model.add(Reshape(target_shape=(28,28,1)))\n",
        "\n",
        "  conv_block(model,filters=3)\n",
        "\n",
        "  conv_block(model,filters=8)\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(15))\n",
        "  model.add(layers.Activation(activations.relu))\n",
        "\n",
        "  model.add(Dense(10))\n",
        "  model.add(layers.Activation(activations.softmax))\n",
        "\n",
        "  model.build(input_shape=(28,28))\n",
        "\n",
        "  return model\n",
        "\n",
        "_, pretrained_weights = tempfile.mkstemp('.tf')\n",
        "\n",
        "model.save_weights(pretrained_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "av4znJKOB68T",
        "outputId": "7cfbfc7b-969b-4434-eba6-ec8603236504"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 4ms/step - loss: 0.3574 - accuracy: 0.8758\n",
            "test loss: 0.3574, test accuracy: 0.8758\n"
          ]
        }
      ],
      "source": [
        "def setup_model():\n",
        "  model = get_model()\n",
        "  model.load_weights(pretrained_weights)\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "## check if setup_model() works\n",
        "_model = setup_model()\n",
        "_ = model_eval(_model) # it works, since test accuracy is consistent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEKfwGRpHfXM"
      },
      "source": [
        "### We'll conduct quantization aware training below\n",
        "### By first make the model \"quantization aware\", then re-compile and fine-tuning it. Last we compare the accuracy and storage size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QE9mBKLwslOh"
      },
      "outputs": [],
      "source": [
        "import tensorflow_model_optimization as tfmot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unv3JB9JwY5U"
      },
      "source": [
        "### Since BatchNorm is not supported by default, we need to pass it to the quantized model by hand"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "jyaPYmhrwhDc"
      },
      "outputs": [],
      "source": [
        "# import necessary functions\n",
        "quantize_annotate_layer = tfmot.quantization.keras.quantize_annotate_layer\n",
        "quantize_annotate_model = tfmot.quantization.keras.quantize_annotate_model\n",
        "quantize_scope = tfmot.quantization.keras.quantize_scope"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "HoNsWGoywzhs"
      },
      "outputs": [],
      "source": [
        "LastValueQuantizer = tfmot.quantization.keras.quantizers.LastValueQuantizer\n",
        "MovingAverageQuantizer = tfmot.quantization.keras.quantizers.MovingAverageQuantizer\n",
        "\n",
        "class BNQuantizeConfig(tfmot.quantization.keras.QuantizeConfig):\n",
        "    # Configure how to quantize weights.\n",
        "    def get_weights_and_quantizers(self, layer):\n",
        "      # by default, all layer are quantized to 8 bit\n",
        "      return [(layer.gamma, MovingAverageQuantizer(num_bits=8, symmetric=True, narrow_range=False, per_axis=False)),(layer.beta, MovingAverageQuantizer(num_bits=8, symmetric=True, narrow_range=False, per_axis=False))]      \n",
        "\n",
        "    def get_activations_and_quantizers(self, layer):\n",
        "      return []\n",
        "\n",
        "    def set_quantize_weights(self, layer, quantize_weights):\n",
        "      layer.gamma=quantize_weights[0]\n",
        "      layer.beta=quantize_weights[1]\n",
        "      #print(quantize_weights,\"\\n\",quantize_weights[0]) ## un-comment this to see how BatchNorm behaves\n",
        "\n",
        "    def set_quantize_activations(self, layer, quantize_activations):\n",
        "      return\n",
        "\n",
        "    def get_output_quantizers(self, layer):\n",
        "      # Does not quantize output, since we return an empty list.\n",
        "      return []\n",
        "\n",
        "    def get_config(self):\n",
        "      return {}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeT2D0B-JFyB"
      },
      "source": [
        "#### Weights would be the same when converting layers to \"quant aware\" layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_Q5q_FaiJFyB"
      },
      "outputs": [],
      "source": [
        "def quantized_model(model):\n",
        "    \n",
        "    model_list = [quantize_annotate_layer(layer,BNQuantizeConfig()) if isinstance(layer,BatchNormalization) else layer for layer in model.layers]\n",
        "    \n",
        "    q_model = quantize_annotate_model(Sequential(model_list))\n",
        "\n",
        "    # check again since it's fancy syntax\n",
        "    # and for print out the summary\n",
        "    q_model.build(input_shape=(None,*x_train[0].shape))\n",
        "    \n",
        "    # `quantize_apply` requires mentioning `xxQuantizeConfig` with `quantize_scope`:\n",
        "    # use **kwargs for better customization ?\n",
        "    with quantize_scope(\n",
        "        {'BNQuantizeConfig': BNQuantizeConfig}):\n",
        "        # Use `quantize_apply` to actually make the model quantization aware.\n",
        "        q_aware = tfmot.quantization.keras.quantize_apply(q_model)\n",
        "\n",
        "    q_aware.summary()\n",
        "\n",
        "    return q_aware\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_zbAAGzJFyD",
        "outputId": "baa5fff9-926a-47b2-a22e-6549f3fe9afb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " quantize_layer (QuantizeLay  (None, 28, 28)           3         \n",
            " er)                                                             \n",
            "                                                                 \n",
            " quant_reshape (QuantizeWrap  (None, 28, 28, 1)        1         \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_conv2d (QuantizeWrapp  (None, 26, 26, 3)        39        \n",
            " erV2)                                                           \n",
            "                                                                 \n",
            " quant_batch_normalization (  (None, 26, 26, 3)        17        \n",
            " QuantizeWrapperV2)                                              \n",
            "                                                                 \n",
            " quant_activation (QuantizeW  (None, 26, 26, 3)        3         \n",
            " rapperV2)                                                       \n",
            "                                                                 \n",
            " quant_conv2d_1 (QuantizeWra  (None, 24, 24, 8)        243       \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_batch_normalization_1  (None, 24, 24, 8)        37        \n",
            "  (QuantizeWrapperV2)                                            \n",
            "                                                                 \n",
            " quant_activation_1 (Quantiz  (None, 24, 24, 8)        3         \n",
            " eWrapperV2)                                                     \n",
            "                                                                 \n",
            " quant_flatten (QuantizeWrap  (None, 4608)             1         \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_dense (QuantizeWrappe  (None, 15)               69136     \n",
            " rV2)                                                            \n",
            "                                                                 \n",
            " quant_activation_2 (Quantiz  (None, 15)               3         \n",
            " eWrapperV2)                                                     \n",
            "                                                                 \n",
            " quant_dense_1 (QuantizeWrap  (None, 10)               165       \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_activation_3 (Quantiz  (None, 10)               1         \n",
            " eWrapperV2)                                                     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 69,652\n",
            "Trainable params: 69,571\n",
            "Non-trainable params: 81\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "q_aware = quantized_model(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nghk6NNkslOm",
        "outputId": "3d703d2f-1b1d-4e64-ec7e-bbfa0926e5f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((1000, 28, 28), (1000,))"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# randomly choose 1000 images out of the training dataset\n",
        "import numpy as np\n",
        "idx = np.random.randint(0,len(x_train),1000)\n",
        "\n",
        "x_train_, y_train_ = x_train[idx], y_train[idx]\n",
        "\n",
        "x_train_.shape, y_train_.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "CTLMOiVwslOo"
      },
      "outputs": [],
      "source": [
        "# define the function to train the quantized model\n",
        "# to not confused with the not quant-aware ones\n",
        "def fit_q_aware(q_aware):\n",
        "  q_aware.compile(optimizer=tf.keras.optimizers.Adam(1e-3),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "  print(\"training\")\n",
        "  q_aware.fit(x_train_,y_train_,batch_size=256,epochs=1,validation_split=0.2)\n",
        "  print(\"\\ntesting\")\n",
        "  # evaluate q_aware\n",
        "  _, q_test_acc = q_aware.evaluate(x_test,y_test)\n",
        "  return q_test_acc\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZ0GpD4it7he"
      },
      "source": [
        "#### Since BatchNorm layer is not supported for q-aware training, the accuracy might be a little unstable (could be off by 1~3%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSuSLodMslOp",
        "outputId": "03b374c7-b9c7-4bc4-c1ad-12c99e3694be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training\n",
            "4/4 [==============================] - 4s 306ms/step - loss: 0.4210 - accuracy: 0.8612 - val_loss: 0.3333 - val_accuracy: 0.9050\n",
            "\n",
            "testing\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.4514 - accuracy: 0.8593\n",
            "\n",
            "Baseline accuracy: 0.8758\n",
            "Quantized accuracy: 0.8593\n"
          ]
        }
      ],
      "source": [
        "# evaluate q_aware\n",
        "q_test_acc = fit_q_aware(q_aware)\n",
        "\n",
        "# Comparison\n",
        "print(\"\\nBaseline accuracy: %.4f\\nQuantized accuracy: %.4f\" % (test_acc,q_test_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "nqdH-Kx5slOr"
      },
      "outputs": [],
      "source": [
        "# convert quant model to tf lite model\n",
        "def quant_to_lite(q_aware):\n",
        "  converter = tf.lite.TFLiteConverter.from_keras_model(q_aware)\n",
        "  converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "  return converter.convert()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Go4M1s0THHJj"
      },
      "source": [
        "#### Seems like the answer to the storage size problem?\n",
        "#### Or not, since there're identical warning in the example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3U91NsjeSRl",
        "outputId": "77dc78b7-fe39-42a3-88e5-2510dd50a0a3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as reshape_layer_call_fn, reshape_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, activation_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ],
      "source": [
        "lite_model = quant_to_lite(q_aware)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "UsxdCXCoslOs"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(interpreter):\n",
        "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "    # Run predictions on every image on the \"test\" dataset.\n",
        "\n",
        "    predictions = np.zeros((len(x_test)))\n",
        "    for i, image in enumerate(x_test):\n",
        "\n",
        "        if i % 1000 == 999:\n",
        "            print('Evaluated on %5d results so far.' % (i+1))\n",
        "\n",
        "        # Pre-processing: add batch dimension and convert to float32 \n",
        "        # to match with the model's input data format\n",
        "        interpreter.set_tensor(input_index,np.expand_dims(image, axis=0).astype(np.float32))\n",
        "\n",
        "        # Run inference.\n",
        "        interpreter.invoke()\n",
        "\n",
        "        # Post-processing: remove batch dimension \n",
        "        # and find the digit with highest probability\n",
        "        output = interpreter.tensor(output_index)\n",
        "        predictions[i] = np.argmax(output()[0])\n",
        "\n",
        "    # Calculate test accuracy\n",
        "    accuracy = (predictions == y_test).mean()\n",
        "    return accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7O-jtV0slOu",
        "outputId": "5253d5a6-5c6d-48c5-f7a1-f27cf0c64b7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluated on  1000 results so far.\n",
            "Evaluated on  2000 results so far.\n",
            "Evaluated on  3000 results so far.\n",
            "Evaluated on  4000 results so far.\n",
            "Evaluated on  5000 results so far.\n",
            "Evaluated on  6000 results so far.\n",
            "Evaluated on  7000 results so far.\n",
            "Evaluated on  8000 results so far.\n",
            "Evaluated on  9000 results so far.\n",
            "Evaluated on 10000 results so far.\n",
            "\n",
            "Quant TFLite test_accuracy: 0.8595\n",
            "Quant TF test accuracy:     0.8593\n"
          ]
        }
      ],
      "source": [
        "def evaluate_lite_model(lite_model):\n",
        "  interpreter = tf.lite.Interpreter(model_content=lite_model)\n",
        "  interpreter.allocate_tensors()\n",
        "  return evaluate_model(interpreter)\n",
        "\n",
        "lite_test_accuracy = evaluate_lite_model(lite_model)\n",
        "print('\\nQuant TFLite test_accuracy: %.4f\\nQuant TF test accuracy: %10.4f'%(lite_test_accuracy, q_test_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "kbOKwB5ae43g"
      },
      "outputs": [],
      "source": [
        "# Create float TFLite model.\n",
        "def model_to_float(model):\n",
        "  float_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "  return float_converter.convert()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-ZOT9mtslOx",
        "outputId": "2eea412c-da56-4314-8677-dcb5b6d62b5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmplmyci1mf/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmplmyci1mf/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Float model in Mb: 0.2691459655761719\n",
            "Quantized model in Mb: 0.0740509033203125\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "float_lite_model = model_to_float(model)\n",
        "\n",
        "def write_file(model_):\n",
        "    _, model_file = tempfile.mkstemp('.tflite')\n",
        "    with open(model_file,'wb') as f:\n",
        "        f.write(model_)\n",
        "    # 2 ** 20 = 1048576\n",
        "    print(\" model in Mb:\", os.path.getsize(model_file) / 1048576.)\n",
        "    \n",
        "print(\"\\nFloat\",end=\"\")\n",
        "write_file(float_lite_model)\n",
        "\n",
        "print(\"Quantized\",end=\"\")\n",
        "write_file(lite_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vQoInj2qC3g"
      },
      "source": [
        "## To see if BatchNorm affects the storage size, I did the following experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "HUSk9tCLJsy8"
      },
      "outputs": [],
      "source": [
        "def model_without_BN(model):\n",
        "  return Sequential([layer for layer in model.layers if not isinstance(layer,BatchNormalization)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "OfuBSCigg2Jt"
      },
      "outputs": [],
      "source": [
        "q2_model = model_without_BN(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcIcBZnyfsQi",
        "outputId": "390c5263-fa0d-442a-dd7d-b310af9e2ead"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape (Reshape)           (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 26, 26, 3)         30        \n",
            "                                                                 \n",
            " activation (Activation)     (None, 26, 26, 3)         0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 24, 24, 8)         224       \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 24, 24, 8)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4608)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 15)                69135     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 15)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                160       \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 69,549\n",
            "Trainable params: 69,549\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "q2_model.build(input_shape=(None,28,28))\n",
        "q2_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1O1QG6IHHJl"
      },
      "source": [
        "### Can we really train for a epoch here after popping out BN?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ni43ji8fHHJl",
        "outputId": "29458fb6-6c9c-4ca0-b582-776a5b088e60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 1s 27ms/step - loss: 1.6800 - accuracy: 0.4600\n"
          ]
        }
      ],
      "source": [
        "q2_model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "_ = q2_model.fit(x_train_[:100],y_train_[:100],epochs=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hgb2GhpchD5L",
        "outputId": "8f4be689-0653-47d2-f917-d9a23223f5a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " quantize_layer_1 (QuantizeL  (None, 28, 28)           3         \n",
            " ayer)                                                           \n",
            "                                                                 \n",
            " quant_reshape (QuantizeWrap  (None, 28, 28, 1)        1         \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_conv2d (QuantizeWrapp  (None, 26, 26, 3)        31        \n",
            " erV2)                                                           \n",
            "                                                                 \n",
            " quant_activation (QuantizeW  (None, 26, 26, 3)        3         \n",
            " rapperV2)                                                       \n",
            "                                                                 \n",
            " quant_conv2d_1 (QuantizeWra  (None, 24, 24, 8)        225       \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_activation_1 (Quantiz  (None, 24, 24, 8)        3         \n",
            " eWrapperV2)                                                     \n",
            "                                                                 \n",
            " quant_flatten (QuantizeWrap  (None, 4608)             1         \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_dense (QuantizeWrappe  (None, 15)               69136     \n",
            " rV2)                                                            \n",
            "                                                                 \n",
            " quant_activation_2 (Quantiz  (None, 15)               3         \n",
            " eWrapperV2)                                                     \n",
            "                                                                 \n",
            " quant_dense_1 (QuantizeWrap  (None, 10)               165       \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_activation_3 (Quantiz  (None, 10)               1         \n",
            " eWrapperV2)                                                     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 69,572\n",
            "Trainable params: 69,549\n",
            "Non-trainable params: 23\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "q2_aware = quantized_model(q2_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYyXSy13JFyH",
        "outputId": "57edbf6f-050f-4154-d226-e232da5d69d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training\n",
            "4/4 [==============================] - 1s 99ms/step - loss: 1.1929 - accuracy: 0.7262 - val_loss: 0.9459 - val_accuracy: 0.8300\n",
            "\n",
            "testing\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.9647 - accuracy: 0.7838\n"
          ]
        }
      ],
      "source": [
        "q2_test_acc = fit_q_aware(q2_aware)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DeDAQ0hhTOB",
        "outputId": "7928a5c3-e65e-416e-e3b9-ddddb11ca209"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as reshape_layer_call_fn, reshape_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, activation_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpnn3hxamk/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpnn3hxamk/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluated on  1000 results so far.\n",
            "Evaluated on  2000 results so far.\n",
            "Evaluated on  3000 results so far.\n",
            "Evaluated on  4000 results so far.\n",
            "Evaluated on  5000 results so far.\n",
            "Evaluated on  6000 results so far.\n",
            "Evaluated on  7000 results so far.\n",
            "Evaluated on  8000 results so far.\n",
            "Evaluated on  9000 results so far.\n",
            "Evaluated on 10000 results so far.\n"
          ]
        }
      ],
      "source": [
        "lite2_test_acc = evaluate_lite_model(quant_to_lite(q2_aware))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtUtYYpEjMpu",
        "outputId": "7ee9a1be-93d8-4515-a0f0-1b00bbdbdcc6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7827"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# result of lite2\n",
        "lite2_test_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLLs7SH-jbLt",
        "outputId": "fbad847b-71f0-4713-f3ac-5416220e3920"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 1.3352 - accuracy: 0.6793\n",
            "test loss: 1.3352, test accuracy: 0.6793\n"
          ]
        }
      ],
      "source": [
        "# check the performance of model2 (model without BatchNorm), shall we?\n",
        "q2_test_acc = model_eval(q2_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rQcPqbGJFyI",
        "outputId": "ceef287b-0d3c-481d-b890-77e6c7edeb39"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as reshape_layer_call_fn, reshape_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, activation_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " model in Mb: 0.0740509033203125\n"
          ]
        }
      ],
      "source": [
        "write_file(quant_to_lite(q_aware))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ap3KaRaRMKPv",
        "outputId": "6acfd8c0-a19b-479b-ddbc-840d455dd145"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as reshape_layer_call_fn, reshape_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, activation_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmplzdn3nch/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmplzdn3nch/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " model in Mb: 0.0713958740234375\n"
          ]
        }
      ],
      "source": [
        "write_file(quant_to_lite(q2_aware))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skiRHl8zqC3k"
      },
      "source": [
        "### It turned out, if we use functional API to build the model, then the model would be compressed correctly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5MAd_ffsEFH"
      },
      "source": [
        "### However, if we use Sequential API aforementioned ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRYs2rBUMZrv",
        "outputId": "941e322c-31e3-4dad-ce36-9b507eacb6df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " quantize_layer_2 (QuantizeL  (None, 28, 28)           3         \n",
            " ayer)                                                           \n",
            "                                                                 \n",
            " quant_reshape_2 (QuantizeWr  (None, 28, 28, 1)        1         \n",
            " apperV2)                                                        \n",
            "                                                                 \n",
            " quant_conv2d_4 (QuantizeWra  (None, 26, 26, 8)        99        \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_batch_normalization_4  (None, 26, 26, 8)        37        \n",
            "  (QuantizeWrapperV2)                                            \n",
            "                                                                 \n",
            " quant_conv2d_5 (QuantizeWra  (None, 24, 24, 8)        603       \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_batch_normalization_5  (None, 24, 24, 8)        37        \n",
            "  (QuantizeWrapperV2)                                            \n",
            "                                                                 \n",
            " quant_flatten_2 (QuantizeWr  (None, 4608)             1         \n",
            " apperV2)                                                        \n",
            "                                                                 \n",
            " quant_dense_4 (QuantizeWrap  (None, 15)               69140     \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_dense_5 (QuantizeWrap  (None, 10)               165       \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 70,086\n",
            "Trainable params: 69,991\n",
            "Non-trainable params: 95\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as reshape_2_layer_call_fn, reshape_2_layer_call_and_return_conditional_losses, conv2d_4_layer_call_fn, conv2d_4_layer_call_and_return_conditional_losses, conv2d_5_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " model in Mb: 0.27286529541015625\n"
          ]
        }
      ],
      "source": [
        "model_ = Sequential([\n",
        "    InputLayer(input_shape=(28,28)),\n",
        "    # RESHAPE LAYER IS IMPORTANT FOR QUANTIZATION\n",
        "    Reshape(target_shape=(28,28,1)),\n",
        "\n",
        "    Conv2D(filters=8, kernel_size=(3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv2D(filters=8, kernel_size=(3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(units=15, activation='relu'),\n",
        "    Dense(units=10, activation=\"softmax\"),    \n",
        "])\n",
        "\n",
        "q3_aware = quantized_model(model_)\n",
        "q3_lite = quant_to_lite(q3_aware)\n",
        "write_file(q3_lite)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jz0VLzk9s1oP"
      },
      "source": [
        "### The storage size shown little to none decrease (size is about 0.279Mb)\n",
        "### I believe this should be more well-documented to increase the accessability of the Tensorflow library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXq-6ZRaHIyx"
      },
      "source": [
        "## Different QuantConfig() settings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wm3C9XFiHhmN"
      },
      "source": [
        "#### Defalult setting of Dense layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "zcEeKzqKsugf"
      },
      "outputs": [],
      "source": [
        "class DefaultDenseQuantizeConfig(tfmot.quantization.keras.QuantizeConfig):\n",
        "    # Configure how to quantize weights.\n",
        "    def get_weights_and_quantizers(self, layer):\n",
        "      return [(layer.kernel, LastValueQuantizer(num_bits=8, symmetric=True, narrow_range=False, per_axis=False))]\n",
        "\n",
        "    # Configure how to quantize activations.\n",
        "    def get_activations_and_quantizers(self, layer):\n",
        "      return [(layer.activation, MovingAverageQuantizer(num_bits=8, symmetric=False, narrow_range=False, per_axis=False))]\n",
        "\n",
        "    def set_quantize_weights(self, layer, quantize_weights):\n",
        "      # Add this line for each item returned in `get_weights_and_quantizers`\n",
        "      # , in the same order\n",
        "      layer.kernel = quantize_weights[0]\n",
        "\n",
        "    def set_quantize_activations(self, layer, quantize_activations):\n",
        "      # Add this line for each item returned in `get_activations_and_quantizers`\n",
        "      # , in the same order.\n",
        "      layer.activation = quantize_activations[0]\n",
        "\n",
        "    # Configure how to quantize outputs (may be equivalent to activations).\n",
        "    def get_output_quantizers(self, layer):\n",
        "      return []\n",
        "\n",
        "    def get_config(self):\n",
        "      return {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDNpYzr6Ic8J"
      },
      "source": [
        "#### Define a new function for custom changes in QuantizeConfig()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "UaF4tCsWJbjG"
      },
      "outputs": [],
      "source": [
        "def quantized_custom_model(model,DenseConfig=DefaultDenseQuantizeConfig,DenseConfig_name='DefaultDenseQuantizeConfig',BNConfig=BNQuantizeConfig,BNConfig_name='BNQuantizeConfig'):\n",
        "\n",
        "    model_list = []\n",
        "    for layer in model.layers:\n",
        "      if isinstance(layer,BatchNormalization):\n",
        "        model_list.append(quantize_annotate_layer(layer,BNConfig()))\n",
        "      elif isinstance(layer,Dense):\n",
        "        model_list.append(quantize_annotate_layer(layer,DenseConfig()))\n",
        "      else:\n",
        "        model_list.append(layer)\n",
        "\n",
        "    # layers besides Dense and BatchNorm\n",
        "    q_model = quantize_annotate_model(Sequential(model_list))\n",
        "\n",
        "    q_model.build(input_shape=(None,28,28))\n",
        "\n",
        "    with quantize_scope(\n",
        "        {DenseConfig_name: DenseConfig,\n",
        "        BNConfig_name: BNConfig}):\n",
        "      q_aware = tfmot.quantization.keras.quantize_apply(q_model)\n",
        "\n",
        "    return q_aware\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqFm7BXFHlYr"
      },
      "source": [
        "#### 4 bit on Dense layer only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "PwkGbEQdHRYy"
      },
      "outputs": [],
      "source": [
        "class Dense4bitQuantizeConfig(DefaultDenseQuantizeConfig):\n",
        "    # Configure how to quantize weights.\n",
        "    def get_weights_and_quantizers(self, layer):\n",
        "      return [(layer.kernel, LastValueQuantizer(num_bits=4, symmetric=True, narrow_range=False, per_axis=False))]\n",
        "\n",
        "    # Configure how to quantize activations.\n",
        "    def get_activations_and_quantizers(self, layer):\n",
        "      return [(layer.activation, MovingAverageQuantizer(num_bits=4, symmetric=False, narrow_range=False, per_axis=False))]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWXCSPKbMCBb"
      },
      "source": [
        "## Was the weight in the original model changed?\n",
        "\n",
        "#### To this concern, we define get_model() function, and get the pretrained model everytime we try new configurations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "IfAWkaMLMh0j"
      },
      "outputs": [],
      "source": [
        "# convert q_aware model to lite model and get the storage size at once\n",
        "def quant_lite_write(qaw):\n",
        "  qlite = quant_to_lite(qaw)\n",
        "  qwac = fit_q_aware(qaw)\n",
        "  print(\"q_aware accuracy: %.4f\\nlite model accuracy: %.4f\" % (qwac,evaluate_lite_model(quant_to_lite(qaw))))\n",
        "  write_file(qlite)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMIkLtJUHRWL",
        "outputId": "b2e3cf9c-e8d6-4ede-d953-ada226c2a16d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 4ms/step - loss: 0.3574 - accuracy: 0.8758\n",
            "test loss: 0.3574, test accuracy: 0.8758\n",
            "0.8758000135421753\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as reshape_3_layer_call_fn, reshape_3_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_6_layer_call_and_return_conditional_losses, activation_8_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training\n",
            "4/4 [==============================] - 2s 142ms/step - loss: 0.4144 - accuracy: 0.8700 - val_loss: 0.3052 - val_accuracy: 0.9200\n",
            "\n",
            "testing\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.4374 - accuracy: 0.8533\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as reshape_3_layer_call_fn, reshape_3_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_6_layer_call_and_return_conditional_losses, activation_8_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluated on  1000 results so far.\n",
            "Evaluated on  2000 results so far.\n",
            "Evaluated on  3000 results so far.\n",
            "Evaluated on  4000 results so far.\n",
            "Evaluated on  5000 results so far.\n",
            "Evaluated on  6000 results so far.\n",
            "Evaluated on  7000 results so far.\n",
            "Evaluated on  8000 results so far.\n",
            "Evaluated on  9000 results so far.\n",
            "Evaluated on 10000 results so far.\n",
            "q_aware accuracy: 0.8533\n",
            "lite model accuracy: 0.8611\n",
            " model in Mb: 0.07410430908203125\n"
          ]
        }
      ],
      "source": [
        "model = setup_model()\n",
        "_ = model_eval(model)\n",
        "print(_)\n",
        "q_d4_aware = quantized_custom_model(model,Dense4bitQuantizeConfig,\"Dense4bitQuantizeConfig\")\n",
        "quant_lite_write(q_d4_aware)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAgEO9IWIEZW"
      },
      "source": [
        "#### 4 bit on BatchNorm only"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Ignore the checkpoint warning since we'd never use any checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "fz2vLGFEHRTP"
      },
      "outputs": [],
      "source": [
        "class BN4bitQuantizeConfig(BNQuantizeConfig):\n",
        "    def get_weights_and_quantizers(self, layer):\n",
        "      return [(layer.gamma, MovingAverageQuantizer(num_bits=4, symmetric=True, narrow_range=False, per_axis=False)),(layer.beta, MovingAverageQuantizer(num_bits=8, symmetric=True, narrow_range=False, per_axis=False))]      \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXCaz4pxIaxc",
        "outputId": "79a03d18-67b5-40c6-e61b-0087707518c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as reshape_4_layer_call_fn, reshape_4_layer_call_and_return_conditional_losses, conv2d_8_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses, activation_12_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training\n",
            "4/4 [==============================] - 2s 147ms/step - loss: 0.4162 - accuracy: 0.8788 - val_loss: 0.5159 - val_accuracy: 0.8650\n",
            "\n",
            "testing\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.6070 - accuracy: 0.8091\n",
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-1.gamma\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-1.gamma\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-1.beta\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-1.beta\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-3.gamma\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-3.gamma\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-3.beta\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-3.beta\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-4.kernel\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-4.kernel\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-4.bias\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-4.bias\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-5.kernel\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-5.kernel\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-5.bias\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-5.bias\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-1.gamma\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-1.gamma\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-1.beta\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-1.beta\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-3.gamma\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-3.gamma\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-3.beta\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-3.beta\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-4.kernel\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-4.kernel\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-4.bias\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-4.bias\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-5.kernel\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-5.kernel\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-5.bias\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-5.bias\n",
            "WARNING:absl:Found untraced functions such as reshape_4_layer_call_fn, reshape_4_layer_call_and_return_conditional_losses, conv2d_8_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses, activation_12_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluated on  1000 results so far.\n",
            "Evaluated on  2000 results so far.\n",
            "Evaluated on  3000 results so far.\n",
            "Evaluated on  4000 results so far.\n",
            "Evaluated on  5000 results so far.\n",
            "Evaluated on  6000 results so far.\n",
            "Evaluated on  7000 results so far.\n",
            "Evaluated on  8000 results so far.\n",
            "Evaluated on  9000 results so far.\n",
            "Evaluated on 10000 results so far.\n",
            "q_aware accuracy: 0.8091\n",
            "lite model accuracy: 0.8087\n",
            " model in Mb: 0.07416534423828125\n"
          ]
        }
      ],
      "source": [
        "model = setup_model()\n",
        "q_b4_aware = quantized_custom_model(model,BNConfig=BN4bitQuantizeConfig,BNConfig_name=\"BN4bitQuantizeConfig\")\n",
        "quant_lite_write(q_b4_aware)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7RgzZquNKJ7"
      },
      "source": [
        "#### 4 bit on BatchNorm and Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVqxhplHNJL4",
        "outputId": "9bfe6240-d46e-41d8-be34-fbc65853918a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-1.gamma\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-1.gamma\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-1.beta\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-1.beta\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-3.gamma\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-3.gamma\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-3.beta\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-3.beta\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-4.kernel\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-4.kernel\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-4.bias\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-4.bias\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-5.kernel\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-5.kernel\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-5.bias\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-5.bias\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-1.gamma\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-1.gamma\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-1.beta\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-1.beta\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-3.gamma\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-3.gamma\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-3.beta\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-3.beta\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-4.kernel\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-4.kernel\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-4.bias\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-4.bias\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-5.kernel\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-5.kernel\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-5.bias\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-5.bias\n",
            "WARNING:absl:Found untraced functions such as reshape_5_layer_call_fn, reshape_5_layer_call_and_return_conditional_losses, conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, activation_16_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training\n",
            "4/4 [==============================] - 2s 279ms/step - loss: 0.4649 - accuracy: 0.8625 - val_loss: 0.5211 - val_accuracy: 0.8650\n",
            "\n",
            "testing\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6210 - accuracy: 0.8010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as reshape_5_layer_call_fn, reshape_5_layer_call_and_return_conditional_losses, conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, activation_16_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluated on  1000 results so far.\n",
            "Evaluated on  2000 results so far.\n",
            "Evaluated on  3000 results so far.\n",
            "Evaluated on  4000 results so far.\n",
            "Evaluated on  5000 results so far.\n",
            "Evaluated on  6000 results so far.\n",
            "Evaluated on  7000 results so far.\n",
            "Evaluated on  8000 results so far.\n",
            "Evaluated on  9000 results so far.\n",
            "Evaluated on 10000 results so far.\n",
            "q_aware accuracy: 0.8010\n",
            "lite model accuracy: 0.8086\n",
            " model in Mb: 0.07419586181640625\n"
          ]
        }
      ],
      "source": [
        "model = setup_model()\n",
        "q_b4_d4_aware = quantized_custom_model(model,Dense4bitQuantizeConfig,\"Dense4bitQuantizeConfig\",BNConfig=BN4bitQuantizeConfig,BNConfig_name=\"BN4bitQuantizeConfig\")\n",
        "quant_lite_write(q_b4_d4_aware)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0K_Z6M-H_-7"
      },
      "source": [
        "#### Fix range algorithm on Dense layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "q63U2M2FHRQk"
      },
      "outputs": [],
      "source": [
        "class FixedRangeQuantizer(tfmot.quantization.keras.quantizers.Quantizer):\n",
        "  \"\"\"Quantizer which forces outputs to be between -1 and 1.\"\"\"\n",
        "\n",
        "  def build(self, tensor_shape, name, layer):\n",
        "    # Not needed. No new TensorFlow variables needed.\n",
        "    return {}\n",
        "\n",
        "  def __call__(self, inputs, training, weights, **kwargs):\n",
        "    return tf.keras.backend.clip(inputs, -1.0, 1.0)\n",
        "\n",
        "  def get_config(self):\n",
        "    # Not needed. No __init__ parameters to serialize.\n",
        "    return {}\n",
        "\n",
        "\n",
        "class ModifiedDenseQuantizeConfig(DefaultDenseQuantizeConfig):\n",
        "    # Configure weights to quantize with 4-bit instead of 8-bits.\n",
        "    def get_weights_and_quantizers(self, layer):\n",
        "      # Use custom algorithm defined in `FixedRangeQuantizer` instead of default Quantizer.\n",
        "      return [(layer.kernel, FixedRangeQuantizer())]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z13kLLzEHRN3",
        "outputId": "b1864eb7-5eff-414f-ff83-1f268858b84e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as reshape_7_layer_call_fn, reshape_7_layer_call_and_return_conditional_losses, conv2d_14_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses, activation_24_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training\n",
            "4/4 [==============================] - 2s 152ms/step - loss: 0.4263 - accuracy: 0.8700 - val_loss: 0.3194 - val_accuracy: 0.8950\n",
            "\n",
            "testing\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.4366 - accuracy: 0.8607\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as reshape_7_layer_call_fn, reshape_7_layer_call_and_return_conditional_losses, conv2d_14_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses, activation_24_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluated on  1000 results so far.\n",
            "Evaluated on  2000 results so far.\n",
            "Evaluated on  3000 results so far.\n",
            "Evaluated on  4000 results so far.\n",
            "Evaluated on  5000 results so far.\n",
            "Evaluated on  6000 results so far.\n",
            "Evaluated on  7000 results so far.\n",
            "Evaluated on  8000 results so far.\n",
            "Evaluated on  9000 results so far.\n",
            "Evaluated on 10000 results so far.\n",
            "q_aware accuracy: 0.8607\n",
            "lite model accuracy: 0.8598\n",
            " model in Mb: 0.074127197265625\n"
          ]
        }
      ],
      "source": [
        "model = setup_model()\n",
        "q_d4_aware_fix = quantized_custom_model(model,ModifiedDenseQuantizeConfig,\"ModifiedDenseQuantizeConfig\")\n",
        "quant_lite_write(q_d4_aware_fix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "7TCgPiXeHRHO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "skiRHl8zqC3k",
        "jz0VLzk9s1oP"
      ],
      "name": "Quantization_aware_training_almost_done_01_exp_algo_1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
